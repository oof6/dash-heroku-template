{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dcc, html, Input, Output, callback, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_mantine_components as dmc\n",
    "from dash_iconify import DashIconify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import plotly.express as px\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. THEME & STYLING (Keep this)\n",
    "# ------------------------------------------------------------------------------\n",
    "theme = {\n",
    "    'background': '#111111',    # Very dark grey\n",
    "    'card_bg': '#1a1a1a',       # Slightly lighter for cards\n",
    "    'text': '#FFFFFF',          # White text\n",
    "    'accent': '#D4AF37',        # Metallic Gold\n",
    "    'accent_secondary': '#C5A028',\n",
    "    'font_family': 'Helvetica, Arial, sans-serif'\n",
    "}\n",
    "\n",
    "# Styles for Tabs to make them Dark/Gold\n",
    "tab_style = {\n",
    "    'borderBottom': f'1px solid {theme[\"accent\"]}',\n",
    "    'padding': '6px',\n",
    "    'backgroundColor': theme['card_bg'],\n",
    "    'color': theme['text']\n",
    "}\n",
    "\n",
    "tab_selected_style = {\n",
    "    'borderTop': f'1px solid {theme[\"accent\"]}',\n",
    "    'borderBottom': '1px solid #111111',\n",
    "    'color': '#000000', \n",
    "    'fontWeight': 'bold',\n",
    "    'padding': '6px'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. DATA LOADING (Old data removed)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Place your new data loading code here\n",
    "df = pd.read_csv('final_data_with_demographics.csv')\n",
    "# Define your two feature sets\n",
    "feature_sets = {\n",
    "    'Size': ['face_height', 'face_width', 'nose_width', 'mouth_width'],\n",
    "    'Ratios': ['face_ratio', 'mouth_nose_ratio', 'eye_ratio', 'golden_score']\n",
    "}\n",
    "\n",
    "# jill df\n",
    "headshots = df.copy() \n",
    "# --------------------------------------------------------\n",
    "# stephanie's code\n",
    "# --------------------------------------------------------\n",
    "predictive_cols = ['face_height', 'face_width', 'nose_width', 'mouth_width']\n",
    "X = df[predictive_cols].copy()\n",
    "y = df['golden_score'].copy()\n",
    "\n",
    "# Train/Test split\n",
    "Xlin_train, Xlin_test, ylin_train, ylin_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', RidgeCV(alphas=np.logspace(-3, 3, 50), cv=5))\n",
    "])\n",
    "ridge_pipe.fit(Xlin_train, ylin_train)\n",
    "\n",
    "#Test metrics\n",
    "ylin_pred_test = ridge_pipe.predict(Xlin_test)\n",
    "R2_TEST= float(r2_score(ylin_test, ylin_pred_test))\n",
    "RMSE_TEST = float(np.sqrt(mean_squared_error(ylin_test, ylin_pred_test)))\n",
    "\n",
    "#Coefficients\n",
    "coef = ridge_pipe.named_steps['ridge'].coef_\n",
    "intercept= float(ridge_pipe.named_steps['ridge'].intercept_)\n",
    "coef_map= dict(zip(predictive_cols, coef))\n",
    "alpha_selected= float(ridge_pipe.named_steps['ridge'].alpha_)\n",
    "\n",
    "# artifacts for callbacks\n",
    "RIDGE_ARTIFACTS = {\n",
    "    'Xlin_train': Xlin_train,\n",
    "    'Xlin_test': Xlin_test,\n",
    "    'ylin_train': ylin_train,\n",
    "    'ylin_test': ylin_test,\n",
    "    'ridge_pipe':ridge_pipe,\n",
    "    'predictive_cols': predictive_cols,\n",
    "    'ylin_pred_test': ylin_pred_test,\n",
    "    'R2_TEST': float(R2_TEST),\n",
    "    'RMSE_TEST': RMSE_TEST,\n",
    "    'coef_map': coef_map,\n",
    "    'intercept': intercept,\n",
    "    'alpha_selected': alpha_selected,\n",
    "}\n",
    "# --------------------------------------------------------\n",
    "# SHEYI's CODE\n",
    "# --------------------------------------------------------\n",
    "faces_cut= pd.read_csv(\"final_data_with_demographics.csv\")\n",
    "\n",
    "# cut golden score into 3 catagories \n",
    "faces_cut[\"golden_score\"]  = pd.qcut(faces_cut[\"golden_score\"], q=3, labels=False)\n",
    "\n",
    "# predictors and predictees\n",
    "X_knn = faces_cut[[\"face_ratio\", \"race\", \"mouth_nose_ratio\",\"eye_ratio\", \"gender\" ]]\n",
    "y_knn = faces_cut[\"golden_score\"]\n",
    "\n",
    "#train and test\n",
    "Xknn_train, Xknn_test, yknn_train, yknn_test = train_test_split(\n",
    "    X_knn, y_knn, test_size=0.25, random_state=42, stratify=y_knn\n",
    ")\n",
    "\n",
    "# numeric \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# catagorical\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# preprocessor \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "        ('cat', categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# initial pipes\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier(weights=\"distance\"))\n",
    "])\n",
    "\n",
    "# fit model \n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": range(1, 20, 2),\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"]\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=4, scoring=\"balanced_accuracy\", n_jobs=-1,error_score='raise')\n",
    "grid.fit(Xknn_train, yknn_train)\n",
    "\n",
    "# find best k \n",
    "results_df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results_df[\"k\"] = results_df[\"param_knn__n_neighbors\"]\n",
    "results_df[\"mean_score\"] = results_df[\"mean_test_score\"]\n",
    "\n",
    "best_k = grid.best_params_[\"knn__n_neighbors\"]\n",
    "best_score = grid.best_score_\n",
    "\n",
    "# --- GOLD STYLE KNN LINE CHART ---\n",
    "bestk_fig = px.line(\n",
    "    results_df,\n",
    "    x=\"k\",\n",
    "    y=\"mean_score\",\n",
    "    title=f\"Cross-Validated Balanced Accuracy vs. K (best k = {best_k})\",\n",
    "    markers=True,\n",
    "    labels={\"k\": \"Number of Neighbors (k)\", \"mean_score\": \"Mean CV Balanced Accuracy\"},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "# Update line color to Gold\n",
    "bestk_fig.update_traces(line_color=theme['accent'], marker_color=theme['accent'])\n",
    "\n",
    "bestk_fig.add_scatter(\n",
    "    x=[best_k],\n",
    "    y=[best_score],\n",
    "    mode=\"markers+text\",\n",
    "    text=[f\"Best k = {best_k}\"],\n",
    "    textposition=\"top center\",\n",
    "    name=\"Best k\",\n",
    "    marker=dict(color='white', size=12, symbol='star') # distinct marker for best K\n",
    ")\n",
    "\n",
    "bestk_fig.update_layout(\n",
    "    plot_bgcolor=theme['card_bg'],\n",
    "    paper_bgcolor=theme['background'],\n",
    "    font_color=theme['text']\n",
    ")\n",
    "\n",
    "#fit with best k \n",
    "pipe2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=best_k,\n",
    "        weights=\"distance\")\n",
    "        )\n",
    "])\n",
    "\n",
    "pipe2.fit(Xknn_train, yknn_train)\n",
    "yknn_pred = pipe2.predict(Xknn_test)\n",
    "\n",
    "knn_acc = accuracy_score(yknn_test, yknn_pred)\n",
    "knn_bal_acc = balanced_accuracy_score(yknn_test, yknn_pred)\n",
    "\n",
    "df_cat= faces_cut.copy()\n",
    "#catagory for discrete colors \n",
    "df_cat['golden_score']= df_cat['golden_score'].astype(\"category\")\n",
    "\n",
    "# --- GOLD PALETTE FOR SCATTER PLOTS ---\n",
    "# Gold, White, Dark Gold\n",
    "gold_discrete_sequence = [theme['accent'], '#FFFFFF', '#FCF6BA']\n",
    "\n",
    "eyeVsMouth = px.scatter(\n",
    "    df_cat, x=\"eye_ratio\", y=\"mouth_nose_ratio\",\n",
    "    title= \"Eye Ratio vs Mouth Nose Ratio\",\n",
    "    color=\"golden_score\",\n",
    "    color_discrete_sequence=gold_discrete_sequence, \n",
    "    symbol=\"golden_score\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "eyeVsMouth.update_layout(plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'])\n",
    "\n",
    "faceVsEye = px.scatter(\n",
    "    df_cat, x=\"face_ratio\", y=\"eye_ratio\", \n",
    "    title=\"Face Ratio vs Eye Ratio\",\n",
    "    color=\"golden_score\",\n",
    "    color_discrete_sequence=gold_discrete_sequence, \n",
    "    symbol=\"golden_score\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "faceVsEye.update_layout(plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'])\n",
    "\n",
    "faceVsMouth = px.scatter(\n",
    "    df_cat, x=\"face_ratio\", y=\"mouth_nose_ratio\",\n",
    "    title=\"Face Ratio vs Mouth Nose Ratio\", \n",
    "    color=\"golden_score\",\n",
    "    color_discrete_sequence=gold_discrete_sequence, \n",
    "    symbol=\"golden_score\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "faceVsMouth.update_layout(plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'])\n",
    "# ---------------------------------------------------------\n",
    "# 2. HELPER FUNCTION: RUN PCA\n",
    "# ---------------------------------------------------------\n",
    "def calculate_pca(feature_list):\n",
    "    \"\"\"\n",
    "    Takes a list of columns, runs PCA, and returns the Scores and Loadings.\n",
    "    \"\"\"\n",
    "    # 1. Select and Standardize\n",
    "    X = df[feature_list].dropna().astype(float)\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    \n",
    "    # 2. Covariance & Eigenvectors\n",
    "    cov_matrix = np.cov(X_std.T)\n",
    "    eigvals, eigvecs = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # 3. Sort Eigenvalues (High to Low)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_vals = eigvals[sorted_indices]\n",
    "    sorted_vecs = eigvecs[:, sorted_indices]\n",
    "    \n",
    "    # 4. Project Data (Get Scores)\n",
    "    scores = X_std @ sorted_vecs\n",
    "    \n",
    "    # 5. Calculate Loadings (Correlation with original variables)\n",
    "    # Loadings = Eigenvector * sqrt(Eigenvalue)\n",
    "    loadings = sorted_vecs * np.sqrt(sorted_vals)\n",
    "    \n",
    "    # Create temporary DataFrames\n",
    "    pc_df = df.loc[X.index].copy()\n",
    "    pc_df['PC1'] = scores[:, 0]\n",
    "    pc_df['PC2'] = scores[:, 1]\n",
    "    \n",
    "    loadings_df = pd.DataFrame(loadings[:, :2], index=feature_list, columns=['PC1', 'PC2'])\n",
    "    \n",
    "    return pc_df, loadings_df, sorted_vals\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. APP INIT\n",
    "# ------------------------------------------------------------------------------\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.DARKLY])\n",
    "server = app.server\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. APP LAYOUT\n",
    "# ------------------------------------------------------------------------------\n",
    "app.layout = html.Div(\n",
    "    style={'backgroundColor': theme['background'], 'minHeight': '100vh', 'padding': '20px'},\n",
    "    children=[\n",
    "        dbc.Container([\n",
    "            \n",
    "            # TITLE (Notice we use className here, but no html.Style block above it)\n",
    "            html.H1(\n",
    "                \"Hot or Not?!\", \n",
    "                className=\"gold-shimmer\",  # <--- This class now works because of the css file\n",
    "                style={'textAlign': 'center', 'marginBottom': '30px'} \n",
    "            ),\n",
    "            \n",
    "            # TABS\n",
    "            dcc.Tabs(id='tabs-on-top', value='tab-7', children=[\n",
    "                \n",
    "                # TAB 1\n",
    "                dcc.Tab(label='About the Data', value='tab-1', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Div([\n",
    "                        html.H3(\"About The Data\", style={'color': theme['accent']}),\n",
    "                        dcc.Markdown(\"\"\"\n",
    "                            ***What is the Golden Ratio?***\n",
    "                                     \n",
    "                                     \n",
    "                            Aesthetics and appearance play a major role in our society today. While there is no true definition of beauty, our ability to find reliable patterns and proportions that extend into art, aesthetics, and ideals of beauty are seen everywhere today. The golden ratio is one of many theories of what makes an object perceived as pleasing. \n",
    "\n",
    "                                          \n",
    "                            The golden ratio is rooted in a mathematical proportion, the Greek letter φ (phi), which is viewed as the ideal proportion. The proportion mathematically works out that one proportion is related to the other by 1.618. This number is derived from the Fibonacci sequence and other instances in nature. \n",
    "                                     \n",
    "                            ***Our Study***\n",
    "                                     \n",
    "\n",
    "                            In the nature of facial aesthetics, the golden ratio is one of many frameworks for perceived attractiveness through balance and harmony in features. Although there are many different ratios that can be viewed and analyzed, in our study ,we focused on measurements between face length to width, eye spacing, and nose to mouth ratio. This is only a subset of the proportions deemed as “ideal”. \n",
    "         \n",
    "\n",
    "                           ***Our Data***\n",
    "                                     \n",
    "\n",
    "                            We created our own dataset using data from our cohort. We collected information such as name, email, race, gender, and a headshot photo from 52 individuals within our cohort. We then used a convolutional neural network including python packages from opencv and mediapipe to build a complete dataset featuring measurements such as mouth width, nose width, face width, and face height. These features were then used to create face and mouth-nose ratios and averaged to create an overall “golden ratio score” or proportionality score. This complete dataframe is used for all of our models. \n",
    "\n",
    "                            ***Complications and Caveats***\n",
    "                                     \n",
    "\n",
    "                            Because of inconsistency in headshot files, posture, and quality of images, not all measurements from all individuals were able to be taken. In addition, small changes in posture and quality could affect our CNNs ability to correctly detect facial features. facial feature detection trial and error with using different networks was frustrating to say the least. OpenCV facial width and height originated as a square, eyebrows would be recognized as noses, background noise from images would be detected as faces themselves, or nothing would be detected at all. We went through over three different CNNs before settling on one and being satisfied that most faces were detected accurately. Moreover, we had a very small sample size, which most likely indicates that our analysis is not an accurate representation of the cohort. \n",
    "\n",
    "              \n",
    "                            \"\"\", style={'color': theme['text']}),\n",
    "                        \n",
    "                        # Github Link\n",
    "                        html.A(\n",
    "                            DashIconify(icon=\"ion:logo-github\", width=30, color=theme['accent']),\n",
    "                            href=\"https://github.com/sek2dcs/DS6021-ML-Final-Project\", # Update with your new link\n",
    "                            target=\"_blank\"\n",
    "                        )\n",
    "                    ], style={'padding': '20px'})\n",
    "                ]),\n",
    "                \n",
    "                # TAB 2\n",
    "                dcc.Tab(label='Dataset', value='tab-2', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Br(),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            html.H3(\"Cohort Data\", style={'color': theme['accent']}),\n",
    "                            dash_table.DataTable(\n",
    "                                id='dataset-table',\n",
    "                                data=df.to_dict('records'),\n",
    "                                columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "                                page_size=10,\n",
    "                                style_table={'overflowX': 'auto'},\n",
    "                                style_header={\n",
    "                                    'backgroundColor': theme['card_bg'],\n",
    "                                    'color': theme['accent'],\n",
    "                                    'fontWeight': 'bold',\n",
    "                                    'border': '1px solid #333'\n",
    "                                },\n",
    "                                style_data={\n",
    "                                    'backgroundColor': theme['background'],\n",
    "                                    'color': theme['text'],\n",
    "                                    'border': '1px solid #333'\n",
    "                                },\n",
    "                            )\n",
    "                        ], width=12),\n",
    "                    ])\n",
    "                ]),\n",
    "                \n",
    "                # TAB 3\n",
    "                dcc.Tab(label='Linear Regression', value='tab-3', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Br(),\n",
    "                    dbc.Container([\n",
    "                    html.H1(\n",
    "                        \"Linear Regression\",\n",
    "                        style={'textAlign': 'center', 'marginBottom': '16px', 'color': theme['accent']}\n",
    "                    ),\n",
    "                    html.H3(\"Research Question:\", style={'color': theme['accent'], 'textAlign': 'center', 'marginBottom': '6px'}),\n",
    "                    html.P(\n",
    "                    \"Do raw facial dimensions contain enough information to find golden ratio without using ratio based features?\",\n",
    "                    style={'color': theme['text'], 'textAlign': 'center', 'fontSize': '18px', 'marginBottom': '24px'}\n",
    "                    ),\n",
    "                    dbc.Row([\n",
    "                    dbc.Col([\n",
    "                        html.Label(\"Select a predictor (for visualization):\", style={'color': theme['text']}),\n",
    "                        dcc.Dropdown(\n",
    "                            id='regression-variable',\n",
    "                            options=[{'label': col, 'value': col} for col in predictive_cols],\n",
    "                            value=predictive_cols[0],\n",
    "                            style={'color': '#000'}\n",
    "                        )\n",
    "                        ], width=6),\n",
    "                    ], className=\"mb-3\"),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([dcc.Graph(id='lm-scatter',style={'height': '500px'})], width=6),\n",
    "                        dbc.Col([dcc.Graph(id='lm-residuals',style={'height': '500px'})], width=6),\n",
    "                    ]),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            html.Div(\n",
    "                                id='model-summary',\n",
    "                                style={\n",
    "                                    'padding': '16px',\n",
    "                                    'backgroundColor': theme['card_bg'],\n",
    "                                    'border': f'1px solid {theme[\"accent\"]}',\n",
    "                                    'borderRadius': '8px',\n",
    "                                    'marginTop': '20px'\n",
    "                                }\n",
    "                            )\n",
    "                         ], width=12)\n",
    "                    ]),\n",
    "                    ], fluid=True)\n",
    "    ]\n",
    "), \n",
    "                \n",
    "                # TAB 4\n",
    "                dcc.Tab(label='Logistic Regression', value='tab-4', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Div([\n",
    "                        html.H3(\"Logistic Regression Model\", style={'color': theme['accent']}),\n",
    "                        html.P(\"Predicting golden ratio categories based on facial features\", style={'color': theme['text']}),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Number of Bins Slider\n",
    "                        html.H4(\"Select Number of Bins\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Slider(\n",
    "                            id='num-bins-slider',\n",
    "                            min=3,\n",
    "                            max=5,\n",
    "                            step=1,\n",
    "                            value=5,\n",
    "                            marks={i: str(i) for i in range(3, 6)},\n",
    "                            tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "                        ),\n",
    "                        html.Br(),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Check Individual's Golden Ratio Bin\n",
    "                        html.H4(\"Check Individual's Golden Ratio Bin\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Dropdown(\n",
    "                            id='person-dropdown',\n",
    "                            options=[{'label': name, 'value': name} for name in sorted(df['name'].unique())],\n",
    "                            placeholder=\"Select a person\",\n",
    "                            style={\n",
    "                                'backgroundColor': '#ffff',  \n",
    "                                'color': '#000000',                 \n",
    "                                'border': '1px solid #333'           \n",
    "                            }\n",
    "                        ),\n",
    "                        html.Div(id='person-bin-output', style={'color': theme['text'], 'marginTop': '10px', 'fontSize': '16px'}),\n",
    "                        html.Br(),\n",
    "                        html.Hr(style={'borderColor': theme['accent']}),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Model Performance Metrics\n",
    "                        html.H4(\"Model Performance\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        html.Div(id='logistic-metrics', style={'color': theme['text'], 'marginBottom': '20px'}),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Confusion Matrix\n",
    "                        html.H4(\"Confusion Matrix\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='logistic-confusion-matrix'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # ROC Curves\n",
    "                        html.H4(\"ROC Curves\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='logistic-roc-curves'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Feature Importance\n",
    "                        html.H4(\"Feature Coefficients by Category\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='logistic-feature-importance'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Ranked Feature Importance\n",
    "                        html.H4(\"Overall Feature Importance\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='logistic-feature-ranked'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Model Coefficients Table\n",
    "                        html.H4(\"Model Coefficients & Intercepts\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dash_table.DataTable(\n",
    "                            id='logistic-coefficients-table',\n",
    "                            style_table={'overflowX': 'auto'},\n",
    "                            style_header={\n",
    "                                'backgroundColor': theme['card_bg'],\n",
    "                                'color': theme['accent'],\n",
    "                                'fontWeight': 'bold',\n",
    "                                'border': '1px solid #333'\n",
    "                            },\n",
    "                            style_data={\n",
    "                                'backgroundColor': theme['background'],\n",
    "                                'color': theme['text'],\n",
    "                                'border': '1px solid #333'\n",
    "                            },\n",
    "                        ),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Conclusions\n",
    "                        html.H4(\"Conclusions\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Markdown(\"\"\"\n",
    "### Logistic Regression Interpretation\n",
    "\n",
    "This logistic regression model answers the question, \"How accurately can a logistic regression model classify individuals in our cohort into golden ratio categories based on their features, and how does the number of bins affect model performance?\"\n",
    "We can see that mouth_nose ratio and face_ratio are the most important coefficients to determine what bin an individual goes in. In the feature importance model, we can see that the bins that lie on the extremities usually have the greatest coefficients.\n",
    "While looking at our confusion matrix, this remains true. Our model does the the best when classifying individuals into the bins that indicate the extremities (very close or very far) but in the moderate category it does not do as well. We can see a similar output in the ROC curves and AUC values. The model does the best when classifying individuals into the extreme bins which is denoted by the ROC curves that are closest to the top left corner and AUC values that are higher and closer to 1.\n",
    "Because our sample size is so small, creating bins was difficult as we needed enough data to be included in the training set and in the test set. That is why our ROC curve looks more similar to a stepwise function - because there is such a limited sample the ROC curve is plotting discrete values.\n",
    "                        \"\"\", style={'color': theme['text'], 'padding': '15px', 'backgroundColor': theme['card_bg'], 'borderRadius': '6px'})\n",
    "                    ], style={'padding': '20px'})\n",
    "                ]),\n",
    "\n",
    "                # TAB 5 \n",
    "                dcc.Tab(label='KNN', value='tab-5', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Div([\n",
    "                        html.H3(\"Question:\", style={'color': theme['accent']}),\n",
    "                        html.P(\"Can the KNN model accurately and consistently group subjects into the right golden score group?\", style={'color': theme['text']}),\n",
    "                        dcc.Graph(\n",
    "                            figure=bestk_fig,\n",
    "                            style={'width': '80%', 'height': 'auto'},\n",
    "                            responsive= True\n",
    "\n",
    "                        ),\n",
    "                        dcc.Slider(id='bestK_slider', min=2, max=10, step=1, value=5, marks={i: str(i) for i in range(2, 11)}, tooltip={\"placement\": \"bottom\", \"always_visible\": True}),\n",
    "                        \n",
    "                        html.Div(id='slider-output-container'),\n",
    "\n",
    "                        #space\n",
    "                        html.Div(style={'height': '20px'}),\n",
    "\n",
    "                        html.Img(src='assets/knn_confusionMatrix.png', style={'width': '60%', 'height': 'auto'}),\n",
    "\n",
    "                    \n",
    "                        \n",
    "                            dbc.Col(\n",
    "                                dcc.Graph(\n",
    "                                    figure= eyeVsMouth,\n",
    "                                    style={'width': 'auto', 'height': '60vh'}\n",
    "                                )\n",
    "                            ),\n",
    "                            dbc.Col(\n",
    "                                dcc.Graph(figure=faceVsEye,style={'width': 'auto', 'height': '60vh'} )\n",
    "                            ),\n",
    "                            dbc.Col(\n",
    "                                dcc.Graph(figure= faceVsMouth ,style={'width': 'auto', 'height': '60vh'})\n",
    "                        \n",
    "                            ),\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        html.H3(\"Conclusion:\", style={'color': theme['accent']}),\n",
    "                        html.P(\"I would say that the KNN model does a pretty good job at correctly clustering items into the correct group since they accuracy is 0.846 and the balanced accuracy is 0.850. The model benefitted from splitting the golden score into 3 buckets instead of 5. I would say there is still some room for improvement.\", style={'color': theme['text']}),\n",
    "\n",
    "                        # Github Link\n",
    "                        html.A(\n",
    "                            DashIconify(icon=\"ion:logo-github\", width=30, color=theme['accent']),\n",
    "                            href=\"#\", # Update with your new link\n",
    "                            target=\"_blank\"\n",
    "                        )\n",
    "                    ], style={'padding': '20px'})\n",
    "                ]), \n",
    "                # TAB 6\n",
    "                dcc.Tab(label='K means', value='tab-6', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Div([\n",
    "                        html.Br(), \n",
    "                        html.H2(\"Are there similarities in face shape between Gender and Sex ?\", style={'color': theme['accent']}), \n",
    "                        dcc.Markdown(\"\"\"\n",
    "                                    Using K means clustering to see if there are natural patterns in the data. Seeing if clusters are affected by data demographics. \n",
    "\n",
    "                                    \n",
    "                                     Please note that elbow/ silhoutte plots state that best fit for this dataset is to use 2 clusters. Included slider to make data more interactive.\n",
    "                                     \"\"\"), \n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # K Value Slider\n",
    "                        html.H4(\"Select Number of Clusters (K)\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Slider(\n",
    "                            id='k-value-slider',\n",
    "                            min=2,max=8, step=1,value=2,\n",
    "                            marks={i: str(i) for i in range(2, 9)},\n",
    "                            tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "                        ),\n",
    "                        html.Br(),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Clusters Visualized\n",
    "                        html.H4(\"K-Means Clusters Visualization\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='cluster-scatter-plot'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Cluster Gender\n",
    "                        html.H4(\"Cluster Distribution by Gender\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='cluster-gender-plot'),\n",
    "                        html.Br(),\n",
    "                        \n",
    "                        # Cluster Race\n",
    "                        html.H4(\"Cluster Distribution by Race\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Graph(id='cluster-race-plot'),\n",
    "                        html.Br(),\n",
    "\n",
    "                        \n",
    "                        # Conclusions\n",
    "                        html.H4(\"Conclusions\", style={'color': theme['accent'], 'marginTop': '20px'}),\n",
    "                        dcc.Markdown(\"\"\"\n",
    "                                    ### K- means model Interpretation\n",
    "\n",
    "                                    K-means clustering is a unsupervised learning technique used to find natural patterns within the data. Our data favors using 2-3 as the number of clusters as per our silhouettte and elbow plot (not included on dashboard). We facial proportions such as face length-width, nose-mouth, and eye ditance ratios as numeric input values. \n",
    "                                    Once clusters were fit we tried to see if there was correlation between the output clusters and the demographics of our sample. \n",
    "                                    While using 2 clusters, you can see patterns of specific genders or races being correlated within different cluster. \n",
    "                                    This leads us to believe that different races and gender are predisposed to different facial features or proportions. \n",
    "                                    In terms of the golden ratio, this could imply that the ratio is biased and therefore an irrealistic standard in our society today \n",
    "                                                                  \n",
    "                        \"\"\", style={'color': theme['text'], 'padding': '15px', 'backgroundColor': theme['card_bg'], 'borderRadius': '6px'})\n",
    "                ])]), \n",
    "                # TAB 7 \n",
    "                dcc.Tab(label='PCA', value='tab-7', style=tab_style, selected_style=tab_selected_style, children=[\n",
    "                    html.Br(),\n",
    "                    html.Div([\n",
    "                        html.Label(\"Select Analysis Model:\", style={'color': theme['text']}),\n",
    "                        dcc.Dropdown(\n",
    "                            id='model-selector',\n",
    "                            options=[\n",
    "                                {'label': 'Size & Dimensions', 'value': 'Size'},\n",
    "                                {'label': 'Ratios & Golden Score', 'value': 'Ratios'}\n",
    "                            ],\n",
    "                            value='Size', \n",
    "                            clearable=False,\n",
    "                            style={'color': '#000'} # Text inside dropdown needs to be black\n",
    "                        )\n",
    "                    ], style={'width': '50%', 'margin': 'auto', 'paddingBottom': '20px'}),\n",
    "    \n",
    "                    # PCA Loadings Table\n",
    "                    html.H4(\"PCA Loadings\", style={'color': theme['accent'], 'textAlign': 'center'}),\n",
    "                    dash_table.DataTable(\n",
    "                        id='loadings-df',\n",
    "                        page_size=10,\n",
    "                        style_table={'overflowX': 'auto', 'marginBottom': '30px'},\n",
    "                        # Add Dark Theme Styling\n",
    "                        style_header={'backgroundColor': theme['card_bg'], 'color': theme['accent'], 'border': '1px solid #333'},\n",
    "                        style_data={'backgroundColor': theme['background'], 'color': theme['text'], 'border': '1px solid #333'},\n",
    "                    ),\n",
    "                    dcc.Graph(id='pca-graph', style={'height': '70vh'}), \n",
    "                    html.Br(), \n",
    "                    html.H4(\"PCA Conclusions\", style={'color': theme['accent'], 'textAlgin': 'center'}), \n",
    "                    dcc.Markdown(\"\"\"\n",
    "                            ***Size & Dimensions PCA***\n",
    "                                 \n",
    "\n",
    "                            The Size & Dimensions PCA model answers the question of how proportional the individual's face is. Based on the biplot, PC1 describes the 'largeness' of one's face. The left side of the x axis indicates people with smaller faces (aka small face height, small face width, small nose width and small mouth width), and the right side of the x axis indicates the opposite. The PC2 in this case mostly showcases the proportion of mouth width to face size. In other words, the top of the y axis indicates a larger face with a relatively narrow mouth, and the bottom of the y axis indicates a smaller face with a relatively wider mouth. The closer the point is to (0,0), the more proportional the mouth width is to face size. \n",
    "\n",
    "                                 \n",
    "                            ***Ratios & Golden Score PCA***\n",
    "                                 \n",
    "\n",
    "                            The Ratio & Golden Score PCA model answers the question of which face ratio and feature ratios are most ideal to fit the golden ratio. Based on the biplot, PC1 describes the relationship of the golden score based on the mouth vs nose ratio. The right side of the x axis indicates wider features, namely a wider mouth than nose. Because the golden score line is also pointing to the right, the right side of the x axis also indicates a higher golden score. The left side of the x axis indicates a wider nose than mouth and a lower golden score. PC2 indicates the face length, with the top of the y axis being longer faces and the bottom of the y axis being shorter faces. There is also the contribution of the eye_ratio variable (which didn't contribute to the golden score), which also shows in the PC2 plot as shorter faces typically having wider set eyes.\n",
    "                            \n",
    "                                 \n",
    "                            The top right of the biplot indicates faces that are the closest to the golden ratio. These faces are typically longer (based on PC2) and more balanced nose/mouth ratio (though leaning more towards a wider mouth versus nose). The top left of the biplot indicates faces that are longer, but have more narrow features, particularly a wider nose than mouth. The bottom right of the biplot indicates shorter faces with wider features (particuarly wider eyes and wider mouth). The bottom right has particuarly good golden scores, but not as good as the top right. The bottom left of the biplot indicates faces that are shorter and have more narrow set features, meaning they have the smallest golden scores. \n",
    "                            In summary, the golden score is the highest for longer faces that have wider features, particularly a wider nose than mouth. \n",
    "                    \n",
    "                            \"\"\", style={'color': theme['text']})\n",
    "                ])\n",
    "            ])\n",
    "        ], fluid=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. CALLBACKS (Old callbacks removed)\n",
    "\n",
    "\n",
    "#Jills code\n",
    "\n",
    "def k_means_func(num_clust):\n",
    "\n",
    "    X = headshots[['face_ratio', 'eye_ratio', 'mouth_nose_ratio']].copy()\n",
    "    X = X.dropna()\n",
    "    \n",
    "    # Get the indices of rows that were used (non-NaN)\n",
    "    valid_indices = X.index\n",
    "\n",
    "    # kmeans\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"kmeans\", KMeans(n_clusters=num_clust, init=\"k-means++\", n_init=10, random_state=123))\n",
    "    ])\n",
    "    pipe.fit(X)\n",
    "    labels = pipe[\"kmeans\"].labels_\n",
    "\n",
    "    # error handing bc i broke it when i put it in dashbaord :/\n",
    "    headshots_clustered = headshots.copy()\n",
    "    if \"cluster\" in headshots_clustered.columns:\n",
    "        headshots_clustered = headshots_clustered.drop(columns=[\"cluster\"])\n",
    "    headshots_clustered[\"cluster\"] = None\n",
    "    headshots_clustered.loc[valid_indices, \"cluster\"] = labels.astype(str)\n",
    "    \n",
    "    headshot3 = headshots_clustered[headshots_clustered[\"cluster\"].notna()][[\"name\", 'race', 'gender', 'cluster', \"golden_score\"]].copy()\n",
    "    \n",
    "    headshot3['cluster'] = headshot3['cluster'].astype(str)\n",
    "    headshot3['gender'] = headshot3['gender'].astype(str).str.strip()\n",
    "    \n",
    "    headshot3 = headshot3.drop_duplicates(subset=['name', 'cluster'], keep='first')\n",
    "    \n",
    "    # Additional check: ensure each person appears only once (take their assigned cluster)\n",
    "    if headshot3['name'].duplicated().any():\n",
    "        headshot3 = headshot3.drop_duplicates(subset=['name'], keep='first')\n",
    "\n",
    "    # Clusters visualized\n",
    "    headshots_plot = headshots_clustered[headshots_clustered[\"cluster\"].notna()].copy()\n",
    "    fig_clusters = px.scatter(\n",
    "        headshots_plot,\n",
    "        x=\"face_ratio\",\n",
    "        y=\"mouth_nose_ratio\",\n",
    "        hover_name=\"name\",\n",
    "        hover_data=[\"name\", 'race', 'gender', 'cluster', \"golden_score\"],\n",
    "        height=650,\n",
    "        color='cluster',\n",
    "        title=\"K-Means Clusters Across Cohort\",\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_clusters.update_layout(\n",
    "        plot_bgcolor=theme['card_bg'],\n",
    "        paper_bgcolor=theme['background'],\n",
    "        font_color=theme['text'])\n",
    "\n",
    "    crosstab = pd.crosstab(headshot3['gender'], headshot3['cluster'], normalize='columns', dropna=False)\n",
    "    \n",
    "    # AI added bc i broke it\n",
    "    cluster_columns = [str(i) for i in range(num_clust)]\n",
    "    for col in cluster_columns:\n",
    "        if col not in crosstab.columns:\n",
    "            crosstab[col] = 0.0\n",
    "    \n",
    "    crosstab = crosstab[cluster_columns]\n",
    "    crosstab = round(crosstab, 2).reset_index()\n",
    "    cluster_gender = pd.melt(crosstab, id_vars='gender', value_vars=cluster_columns, \n",
    "                            var_name='cluster', value_name='value')\n",
    "    cluster_gender = cluster_gender.drop_duplicates(subset=['gender', 'cluster'])\n",
    "    cluster_gender = cluster_gender.sort_values(['cluster', 'gender'])\n",
    "    cluster_gender['percentage'] = (cluster_gender['value'] * 100).round(1)\n",
    "    cluster_gender['bar_text'] = cluster_gender['percentage'].apply(lambda x: str(int(round(x, 0)))) + \"%\"\n",
    "\n",
    "    fig_cluster_gender = px.bar(\n",
    "        cluster_gender, x='cluster', y='value', color='gender',\n",
    "        text='bar_text',barmode='group',\n",
    "        title=\"Cluster Distribution by Gender\",\n",
    "        labels={'value': 'Proportion', 'cluster': 'Cluster'},\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_cluster_gender.update_layout(\n",
    "        showlegend=True,\n",
    "        plot_bgcolor=theme['card_bg'],\n",
    "        paper_bgcolor=theme['background'],\n",
    "        font_color=theme['text']\n",
    "    )\n",
    "\n",
    "    # Cluster race \n",
    "    cluster_race = round(pd.crosstab(headshot3['cluster'], headshot3['race'], normalize='columns'), 2).reset_index()\n",
    "    cluster_race = pd.melt(cluster_race, id_vars='cluster', \n",
    "        value_vars=['asian', 'black or african american', 'hispanic or latino',\n",
    "                    'middle eastern or north african', 'other/mixed', 'white/caucasian']\n",
    "    )\n",
    "    cluster_race['percentage'] = (cluster_race['value'] * 100).round(1)\n",
    "    cluster_race['bar_text'] = cluster_race['percentage'].apply(lambda x: str(int(round(x, 0)))) + \"%\"\n",
    "\n",
    "    fig_cluster_race = px.bar(\n",
    "        cluster_race,x='cluster',  y='value', color='race',\n",
    "        text='bar_text', barmode='group', width=900, height=400,\n",
    "        title=\"Cluster Distribution by Race\",\n",
    "        labels={'value': 'Proportion', 'cluster': 'Cluster'},\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_cluster_race.update_layout(\n",
    "        showlegend=True,\n",
    "        plot_bgcolor=theme['card_bg'],\n",
    "        paper_bgcolor=theme['background'],\n",
    "        font_color=theme['text']\n",
    "    )\n",
    "    \n",
    "    return fig_clusters, fig_cluster_gender, fig_cluster_race\n",
    "# bella code\n",
    "BIN_LABELS = {\n",
    "    3: ['Close', 'Moderate', 'Far'],\n",
    "    4: ['Very Close', 'Close', 'Moderate', 'Far'],\n",
    "    5: ['Very Close', 'Close', 'Moderate', 'Far', 'Very Far']\n",
    "}\n",
    "\n",
    "def recategorize_y(df, num_bins):\n",
    "    \"\"\"Bin golden_score into meaningful class names based on number of bins\"\"\"\n",
    "    labels = BIN_LABELS[num_bins]\n",
    "    quantiles = [df['golden_score'].quantile(i / num_bins) for i in range(1, num_bins)]\n",
    "    df['golden_ratio_category'] = pd.cut(\n",
    "        df['golden_score'],\n",
    "        bins=[-float('inf')] + quantiles + [float('inf')],\n",
    "        labels=labels\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Remove rows with missing face measurements or golden_score\n",
    "df_clean = df.dropna(subset=['face_width', 'face_height', 'golden_score']).copy()\n",
    "\n",
    "# Calculate face ratio (height/width) - already exists but recalculating for consistency\n",
    "df_clean['face_ratio'] = df_clean['face_height'] / df_clean['face_width']\n",
    "\n",
    "# Standardize pixel measurements by converting to ratios relative to face width\n",
    "df_clean['nose_to_face_ratio'] = df_clean['nose_width'] / df_clean['face_width']\n",
    "df_clean['mouth_to_face_ratio'] = df_clean['mouth_width'] / df_clean['face_width']\n",
    "\n",
    "# Initial categorization with 5 bins (default)\n",
    "df_clean = recategorize_y(df_clean.copy(), 5)\n",
    "\n",
    "# Since headshots are different sizes, we'll use ratios instead of raw pixel measurements\n",
    "# This standardizes the features across different image sizes\n",
    "# Select ratio-based features (standardized to be size-independent)\n",
    "ratio_features = ['face_ratio', 'mouth_nose_ratio', 'eye_ratio', \n",
    "                  'nose_to_face_ratio', 'mouth_to_face_ratio']\n",
    "\n",
    "# Use rows where we have at least face_width and face_height\n",
    "df_model = df_clean.dropna(subset=['face_width', 'face_height']).copy()\n",
    "\n",
    "# Handle missing values in ratio features by imputing with median\n",
    "for col in ratio_features:\n",
    "    if col in df_model.columns and df_model[col].isnull().sum() > 0:\n",
    "        median_val = df_model[col].median()\n",
    "        df_model[col] = df_model[col].fillna(median_val)\n",
    "\n",
    "# Encode categorical variables (gender, race) if they exist\n",
    "# Check unique values in gender\n",
    "if 'gender' in df_model.columns:\n",
    "    # Create dummy variables for gender\n",
    "    gender_dummies = pd.get_dummies(df_model['gender'], prefix='gender')\n",
    "    df_model = pd.concat([df_model, gender_dummies], axis=1)\n",
    "    ratio_features = ratio_features + list(gender_dummies.columns)\n",
    "\n",
    "# Update feature columns to include all ratio features\n",
    "feature_columns = [col for col in ratio_features if col in df_model.columns]\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_model[feature_columns]\n",
    "y = df_model['golden_ratio_category']\n",
    "\n",
    "# Split the data\n",
    "# Note: Not using stratify because some categories may have very few samples\n",
    "# which would cause an error with stratified splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features (important for logistic regression)\n",
    "# Even though we're using ratios, StandardScaler ensures all features are on the same scale\n",
    "# This is especially important when features have different ranges\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "# Using multinomial for multi-class classification\n",
    "logistic_model = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = logistic_model.predict(X_train_scaled)\n",
    "y_test_pred = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=logistic_model.classes_,\n",
    "    columns=logistic_model.classes_\n",
    ")\n",
    "\n",
    "confusion_matrix_graph = px.imshow(\n",
    "    cm_df,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Blues',\n",
    "    labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Count\"),\n",
    "    title=\"Confusion Matrix - Test Set\"\n",
    ")\n",
    "confusion_matrix_graph.update_layout(\n",
    "    plot_bgcolor=theme['card_bg'],\n",
    "    paper_bgcolor=theme['background'],\n",
    "    font_color=theme['text']\n",
    ")\n",
    "\n",
    "# Get predicted probabilities for test set\n",
    "y_test_proba = logistic_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Binarize the labels for multiclass ROC (one-vs-rest approach)\n",
    "y_test_binarized = label_binarize(y_test, classes=logistic_model.classes_)\n",
    "n_classes = len(logistic_model.classes_)\n",
    "\n",
    "# Calculate ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calculate micro-averaged ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_test_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Calculate macro-averaged AUC\n",
    "roc_auc[\"macro\"] = roc_auc_score(y_test_binarized, y_test_proba, average='macro', multi_class='ovr')\n",
    "\n",
    "# Create figure\n",
    "roc_curve_graph = go.Figure()\n",
    "\n",
    "# Colors for the classes\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "\n",
    "# Add ROC curves for each class\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    roc_curve_graph.add_trace(\n",
    "        go.Scatter(\n",
    "            x=fpr[i],\n",
    "            y=tpr[i],\n",
    "            mode='lines',\n",
    "            line=dict(color=color, width=2),\n",
    "            name=f\"ROC curve for {logistic_model.classes_[i]} (AUC = {roc_auc[i]:.3f})\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add micro-average ROC curve\n",
    "roc_curve_graph.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr[\"micro\"],\n",
    "        y=tpr[\"micro\"],\n",
    "        mode='lines',\n",
    "        line=dict(color='deeppink', width=2, dash='dash'),\n",
    "        name=f\"Micro-averaged ROC (AUC = {roc_auc['micro']:.3f})\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add diagonal random classifier line\n",
    "roc_curve_graph.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode='lines',\n",
    "        line=dict(color='black', width=1, dash='dash'),\n",
    "        name=\"Random Classifier (AUC = 0.500)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "roc_curve_graph.update_layout(\n",
    "    title=\"ROC Curves for Multiclass Logistic Regression Model\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    width=900,\n",
    "    height=700,\n",
    "    plot_bgcolor=theme['card_bg'],\n",
    "    paper_bgcolor=theme['background'],\n",
    "    font_color=theme['text'],\n",
    "    legend=dict(\n",
    "        bgcolor=theme['card_bg'],\n",
    "        bordercolor=theme['accent']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get feature coefficients for each class\n",
    "coefficients = logistic_model.coef_\n",
    "feature_names = feature_columns\n",
    "\n",
    "# Create a DataFrame to visualize feature importance\n",
    "coef_df = pd.DataFrame(\n",
    "    coefficients.T,\n",
    "    index=feature_names,\n",
    "    columns=logistic_model.classes_\n",
    ")\n",
    "\n",
    "coef_long = coef_df.drop(columns=['avg_abs_coef'], errors='ignore').reset_index()\n",
    "coef_long = coef_long.melt(id_vars='index',\n",
    "                           var_name='Class',\n",
    "                           value_name='Coefficient')\n",
    "coef_long.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "\n",
    "# Create grouped bar chart\n",
    "feature_importance_graph = px.bar(\n",
    "    coef_long,\n",
    "    x='Feature',\n",
    "    y='Coefficient',\n",
    "    color='Class',\n",
    "    barmode='group',\n",
    "    title='Feature Coefficients by Golden Ratio Category',\n",
    ")\n",
    "feature_importance_graph.update_layout(\n",
    "    plot_bgcolor=theme['card_bg'],\n",
    "    paper_bgcolor=theme['background'],\n",
    "    font_color=theme['text'],\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Coefficient Value\",\n",
    "    legend_title=\"Category\",\n",
    "    xaxis=dict(tickangle=45)\n",
    ")\n",
    "\n",
    "# Calculate average absolute coefficient for overall feature importance\n",
    "coef_df['avg_abs_coef'] = coef_df.abs().mean(axis=1)\n",
    "coef_df_sorted = coef_df.sort_values('avg_abs_coef', ascending=False)\n",
    "\n",
    "coef_ranked = coef_df_sorted[['avg_abs_coef']].reset_index()\n",
    "\n",
    "feature_importance_ranked_graph = px.bar(\n",
    "    coef_ranked,\n",
    "    x='index',\n",
    "    y='avg_abs_coef',\n",
    "    title='Overall Feature Importance (Average Absolute Coefficient)',\n",
    "    labels={'index': 'Feature', 'avg_abs_coef': 'Importance'},\n",
    ")\n",
    "feature_importance_ranked_graph.update_layout(\n",
    "    plot_bgcolor=theme['card_bg'],\n",
    "    paper_bgcolor=theme['background'],\n",
    "    font_color=theme['text'],\n",
    "    xaxis=dict(tickangle=45)\n",
    ")\n",
    "\n",
    "# Create model coefficients table data\n",
    "coef_table_df = pd.DataFrame(\n",
    "    logistic_model.coef_,\n",
    "    index=logistic_model.classes_,\n",
    "    columns=feature_columns\n",
    ")\n",
    "intercept_df = pd.DataFrame(\n",
    "    logistic_model.intercept_,\n",
    "    index=logistic_model.classes_,\n",
    "    columns=[\"Intercept\"]\n",
    ")\n",
    "model_details_df = pd.concat([coef_table_df, intercept_df], axis=1)\n",
    "model_details_df.reset_index(inplace=True)\n",
    "model_details_df.rename(columns={'index': 'Class'}, inplace=True)\n",
    "\n",
    "# bella callback\n",
    "@app.callback(\n",
    "    Output('logistic-metrics', 'children'),\n",
    "    Output('logistic-confusion-matrix', 'figure'),\n",
    "    Output('logistic-roc-curves', 'figure'),\n",
    "    Output('logistic-feature-importance', 'figure'),\n",
    "    Output('logistic-feature-ranked', 'figure'),\n",
    "    Output('logistic-coefficients-table', 'columns'),\n",
    "    Output('logistic-coefficients-table', 'data'),\n",
    "    Input('tabs-on-top', 'value'),\n",
    "    Input('num-bins-slider', 'value')\n",
    ")\n",
    "def update_logistic_plots(tab_value, num_bins):\n",
    "    if tab_value == 'tab-4':\n",
    "        df_binned = recategorize_y(df_clean.copy(), num_bins)\n",
    "        target_col = 'golden_ratio_category'\n",
    "        ratio_features = ['face_ratio', 'mouth_nose_ratio', 'eye_ratio', 'nose_to_face_ratio', 'mouth_to_face_ratio']\n",
    "        df_model_binned = df_binned.dropna(subset=['face_width', 'face_height']).copy()\n",
    "        for col in ratio_features:\n",
    "            if col in df_model_binned.columns and df_model_binned[col].isnull().sum() > 0:\n",
    "                median_val = df_model_binned[col].median()\n",
    "                df_model_binned[col] = df_model_binned[col].fillna(median_val)\n",
    "        \n",
    "        if 'gender' in df_model_binned.columns:\n",
    "            gender_dummies = pd.get_dummies(df_model_binned['gender'], prefix='gender')\n",
    "            df_model_binned = pd.concat([df_model_binned, gender_dummies], axis=1)\n",
    "            ratio_features_binned = ratio_features + list(gender_dummies.columns)\n",
    "        else:\n",
    "            ratio_features_binned = ratio_features\n",
    "        \n",
    "        feature_columns_binned = [col for col in ratio_features_binned if col in df_model_binned.columns]\n",
    "        X_binned = df_model_binned[feature_columns_binned]\n",
    "        y_binned = df_model_binned[target_col]\n",
    "        X_train_binned, X_test_binned, y_train_binned, y_test_binned = train_test_split(X_binned, y_binned, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler_binned = StandardScaler()\n",
    "        X_train_scaled_binned = scaler_binned.fit_transform(X_train_binned)\n",
    "        X_test_scaled_binned = scaler_binned.transform(X_test_binned)\n",
    "        \n",
    "        model_binned = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "        model_binned.fit(X_train_scaled_binned, y_train_binned)\n",
    "        \n",
    "        y_train_pred_binned = model_binned.predict(X_train_scaled_binned)\n",
    "        y_test_pred_binned = model_binned.predict(X_test_scaled_binned)\n",
    "        train_accuracy_binned = accuracy_score(y_train_binned, y_train_pred_binned)\n",
    "        test_accuracy_binned = accuracy_score(y_test_binned, y_test_pred_binned)\n",
    "        \n",
    "        metrics_text = html.Div([\n",
    "            html.P(f\"Training Accuracy: {train_accuracy_binned:.4f} ({train_accuracy_binned*100:.2f}%)\", style={'fontSize': '16px', 'margin': '5px 0'}),\n",
    "            html.P(f\"Test Accuracy: {test_accuracy_binned:.4f} ({test_accuracy_binned*100:.2f}%)\", style={'fontSize': '16px', 'margin': '5px 0'}),\n",
    "        ])\n",
    "        \n",
    "        # --- 1. GOLD CONFUSION MATRIX ---\n",
    "        cm_binned = confusion_matrix(y_test_binned, y_test_pred_binned, labels=model_binned.classes_)\n",
    "        cm_df_binned = pd.DataFrame(cm_binned, index=model_binned.classes_, columns=model_binned.classes_)\n",
    "        \n",
    "        # Custom Black to Gold Color Scale\n",
    "        gold_scale = [[0, '#000000'], [1, theme['accent']]]\n",
    "        \n",
    "        confusion_matrix_graph_binned = px.imshow(\n",
    "            cm_df_binned, text_auto=True, \n",
    "            color_continuous_scale=gold_scale, # Applied Gold Scale\n",
    "            labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Count\"),\n",
    "            title=\"Confusion Matrix - Test Set\",\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        confusion_matrix_graph_binned.update_layout(plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'])\n",
    "        \n",
    "        # --- 2. GOLD ROC CURVES ---\n",
    "        y_test_proba_binned = model_binned.predict_proba(X_test_scaled_binned)\n",
    "        y_test_binarized_binned = label_binarize(y_test_binned, classes=model_binned.classes_)\n",
    "        n_classes_binned = len(model_binned.classes_)\n",
    "        fpr_binned, tpr_binned, roc_auc_binned = dict(), dict(), dict()\n",
    "        \n",
    "        for i in range(n_classes_binned):\n",
    "            fpr_binned[i], tpr_binned[i], _ = roc_curve(y_test_binarized_binned[:, i], y_test_proba_binned[:, i])\n",
    "            roc_auc_binned[i] = auc(fpr_binned[i], tpr_binned[i])\n",
    "        \n",
    "        fpr_binned[\"micro\"], tpr_binned[\"micro\"], _ = roc_curve(y_test_binarized_binned.ravel(), y_test_proba_binned.ravel())\n",
    "        roc_auc_binned[\"micro\"] = auc(fpr_binned[\"micro\"], tpr_binned[\"micro\"])\n",
    "        \n",
    "        roc_curve_graph_binned = go.Figure()\n",
    "        \n",
    "        # Distinct Gold-ish colors for lines\n",
    "        colors_binned = [theme['accent'], '#FFFFFF', theme['accent_secondary'], '#FFEA00', '#fcf6ba']\n",
    "        \n",
    "        for i, color in zip(range(n_classes_binned), colors_binned[:n_classes_binned]):\n",
    "            roc_curve_graph_binned.add_trace(go.Scatter(\n",
    "                x=fpr_binned[i], y=tpr_binned[i], mode='lines',\n",
    "                line=dict(color=color, width=2),\n",
    "                name=f\"ROC curve for {model_binned.classes_[i]} (AUC = {roc_auc_binned[i]:.3f})\"\n",
    "            ))\n",
    "        \n",
    "        roc_curve_graph_binned.add_trace(go.Scatter(\n",
    "            x=fpr_binned[\"micro\"], y=tpr_binned[\"micro\"], mode='lines',\n",
    "            line=dict(color='white', width=2, dash='dash'), # Changed to White\n",
    "            name=f\"Micro-averaged ROC (AUC = {roc_auc_binned['micro']:.3f})\"\n",
    "        ))\n",
    "        \n",
    "        roc_curve_graph_binned.add_trace(go.Scatter(\n",
    "            x=[0, 1], y=[0, 1], mode='lines',\n",
    "            line=dict(color='grey', width=1, dash='dash'),\n",
    "            name=\"Random Classifier\"\n",
    "        ))\n",
    "        \n",
    "        roc_curve_graph_binned.update_layout(\n",
    "            title=\"ROC Curves\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\",\n",
    "            width=900, height=700,\n",
    "            plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'],\n",
    "            legend=dict(bgcolor=theme['card_bg'], bordercolor=theme['accent'])\n",
    "        )\n",
    "        \n",
    "        # --- 3. GOLD BAR CHARTS ---\n",
    "        coefficients_binned = model_binned.coef_\n",
    "        coef_df_binned = pd.DataFrame(coefficients_binned.T, index=feature_columns_binned, columns=model_binned.classes_)\n",
    "        coef_long_binned = coef_df_binned.drop(columns=['avg_abs_coef'], errors='ignore').reset_index().melt(id_vars='index', var_name='Class', value_name='Coefficient')\n",
    "        coef_long_binned.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "        \n",
    "        feature_importance_graph_binned = px.bar(\n",
    "            coef_long_binned, x='Feature', y='Coefficient', color='Class',\n",
    "            barmode='group', title='Feature Coefficients',\n",
    "            color_discrete_sequence=colors_binned, # Apply Gold Palette\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        feature_importance_graph_binned.update_layout(\n",
    "            plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'],\n",
    "            xaxis=dict(tickangle=45)\n",
    "        )\n",
    "        \n",
    "        # Ranked Importance\n",
    "        coef_df_binned['avg_abs_coef'] = coef_df_binned.abs().mean(axis=1)\n",
    "        coef_ranked_binned = coef_df_binned.sort_values('avg_abs_coef', ascending=False)[['avg_abs_coef']].reset_index()\n",
    "        \n",
    "        feature_importance_ranked_graph_binned = px.bar(\n",
    "            coef_ranked_binned, x='index', y='avg_abs_coef',\n",
    "            title='Overall Feature Importance',\n",
    "            labels={'index': 'Feature', 'avg_abs_coef': 'Importance'},\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        # Force bars to be solid Gold\n",
    "        feature_importance_ranked_graph_binned.update_traces(marker_color=theme['accent']) \n",
    "        feature_importance_ranked_graph_binned.update_layout(\n",
    "            plot_bgcolor=theme['card_bg'], paper_bgcolor=theme['background'], font_color=theme['text'],\n",
    "            xaxis=dict(tickangle=45)\n",
    "        )\n",
    "        \n",
    "        # Table\n",
    "        coef_table_df_binned = pd.DataFrame(model_binned.coef_, index=model_binned.classes_, columns=feature_columns_binned)\n",
    "        intercept_df_binned = pd.DataFrame(model_binned.intercept_, index=model_binned.classes_, columns=[\"Intercept\"])\n",
    "        model_details_df_binned = pd.concat([coef_table_df_binned, intercept_df_binned], axis=1).reset_index().rename(columns={'index': 'Class'})\n",
    "        columns = [{\"name\": i, \"id\": i} for i in model_details_df_binned.columns]\n",
    "        data = model_details_df_binned.to_dict('records')\n",
    "        \n",
    "        return (metrics_text, confusion_matrix_graph_binned, roc_curve_graph_binned, \n",
    "                feature_importance_graph_binned, feature_importance_ranked_graph_binned, columns, data)\n",
    "\n",
    "    empty_fig = {'data': [], 'layout': {'title': 'Select Logistic Regression tab to view'}}\n",
    "    return (html.Div(\"\"), empty_fig, empty_fig, empty_fig, empty_fig, [], [])\n",
    "# bella callback pt 2\n",
    "@app.callback(\n",
    "    Output('person-bin-output', 'children'),\n",
    "    Input('person-dropdown', 'value'),\n",
    "    Input('num-bins-slider', 'value')\n",
    ")\n",
    "def show_person_bin(selected_name, num_bins):\n",
    "    if selected_name is None:\n",
    "        return \"\"\n",
    "    df_binned = recategorize_y(df_clean.copy(), num_bins)\n",
    "    person_row = df_binned[df_binned['name'] == selected_name]\n",
    "    if person_row.empty:\n",
    "        return f\"No data found for {selected_name}\"\n",
    "    bin_name = person_row['golden_ratio_category'].values[0]\n",
    "    return f\"{selected_name} is in the '{bin_name}' bin\"\n",
    "\n",
    "# sophie callback\n",
    "@app.callback(\n",
    "    Output('pca-graph', 'figure'),\n",
    "    Output('loadings-df', 'data'),\n",
    "    Output('loadings-df', 'columns'),\n",
    "    Input('model-selector', 'value')\n",
    ")\n",
    "def update_graph(selected_model):\n",
    "    # 1. Run PCA\n",
    "    features = feature_sets[selected_model]\n",
    "    pc_df, loadings_df, eigvals = calculate_pca(features)\n",
    "    \n",
    "    loadings_df = loadings_df.reset_index().rename(columns={'index': 'Feature'})\n",
    "    \n",
    "    # 2. Base Plot\n",
    "    fig = px.scatter(pc_df, x='PC1', y='PC2', \n",
    "                     hover_name='name',\n",
    "                     hover_data=features + ['race', 'gender'], \n",
    "                     title=f\"PCA Biplot: {selected_model}\",\n",
    "                     template='plotly_dark')\n",
    "\n",
    "    # --- UPDATE DOTS TO GOLD ---\n",
    "    fig.update_traces(marker=dict(color=theme['accent'], size=8))\n",
    "\n",
    "    # 3. Add Arrows\n",
    "    scale_factor = max(pc_df['PC1'].max(), pc_df['PC2'].max()) \n",
    "    \n",
    "    for i, row in loadings_df.iterrows():\n",
    "        var_name = row['Feature']\n",
    "        x_end = row['PC1'] * scale_factor * 0.8\n",
    "        y_end = row['PC2'] * scale_factor * 0.8\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[0, x_end], y=[0, y_end],\n",
    "            mode='lines+text',\n",
    "            name=var_name,\n",
    "            text=[None, var_name],\n",
    "            textposition=\"top center\",\n",
    "            line=dict(width=3, color='white') # Arrows in White to contrast against Gold dots\n",
    "        ))\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=x_end, y=y_end, ax=0, ay=0, xref=\"x\", yref=\"y\",\n",
    "            showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=2, arrowcolor='white'\n",
    "        )\n",
    "\n",
    "    # 4. Polish Layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        showlegend=False,\n",
    "        paper_bgcolor=theme['background'],\n",
    "        plot_bgcolor=theme['background'],\n",
    "        font_color=theme['text']\n",
    "    )\n",
    "    \n",
    "    display_df = loadings_df.round(4)\n",
    "    columns = [{\"name\": i, \"id\": i} for i in display_df.columns]\n",
    "    data = display_df.to_dict('records')\n",
    "\n",
    "    return fig, data, columns\n",
    "\n",
    "# sheyi's callback\n",
    "@callback(\n",
    "    Output('slider-output-container', 'children'),\n",
    "    Input('bestK_slider', 'value'))\n",
    "def update_output(value):\n",
    "    pipe3 = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('knn', KNeighborsClassifier(\n",
    "            n_neighbors=value,\n",
    "            weights=\"distance\")\n",
    "            )\n",
    "    ])\n",
    "    pipe3.fit(Xknn_train, yknn_train)\n",
    "    yknn_pred = pipe3.predict(Xknn_test)\n",
    "    \n",
    "    knn_accacc = accuracy_score(yknn_test, yknn_pred)\n",
    "    knn_bal_acc = balanced_accuracy_score(yknn_test, yknn_pred)\n",
    "    val = f\"Accuracy: {knn_acc:.3f}\", f\"Balanced accuracy: {knn_bal_acc:.3f}\"\n",
    "\n",
    "    return f\"Accuracy: {knn_acc:.3f}   \", f\"Balanced accuracy: {knn_bal_acc:.3f}\"\n",
    "\n",
    "# jills callbacks\n",
    "@app.callback(\n",
    "    Output('cluster-scatter-plot', 'figure'),\n",
    "    Output('cluster-gender-plot', 'figure'),\n",
    "    Output('cluster-race-plot', 'figure'),\n",
    "    Input('tabs-on-top', 'value'),\n",
    "    Input('k-value-slider', 'value')\n",
    ")\n",
    "def update_cluster_plots(tab_value, k_value):\n",
    "    if tab_value == 'tab-6':\n",
    "        fig_clusters, fig_cluster_gender, fig_cluster_race = k_means_func(k_value)\n",
    "        return fig_clusters, fig_cluster_gender, fig_cluster_race\n",
    "    empty_fig = {'data': [], 'layout': {'title': 'Select K-means tab to view'}}\n",
    "    return empty_fig, empty_fig, empty_fig\n",
    "\n",
    "\n",
    "# stephanie's callback \n",
    "@app.callback(\n",
    "    [\n",
    "        Output('lm-scatter', 'figure'),\n",
    "        Output('lm-residuals', 'figure'),\n",
    "        Output('model-summary', 'children'),\n",
    "    ],\n",
    "    [Input('regression-variable', 'value')]\n",
    ")\n",
    "def update_linear_tab(selected_feature):\n",
    "    # 1. Safety Check\n",
    "    if not selected_feature:\n",
    "        return go.Figure(), go.Figure(), \"Please select a feature.\"\n",
    "\n",
    "    # 2. Prepare Single-Feature Data (Reshaping is crucial here)\n",
    "    # We use the global Xlin_train/test variables defined earlier\n",
    "    x_train_feat = Xlin_train[[selected_feature]].values\n",
    "    x_test_feat  = Xlin_test[[selected_feature]].values\n",
    "    y_train_vec  = ylin_train.values\n",
    "    y_test_vec   = ylin_test.values\n",
    "\n",
    "    # 3. Train Single-Feature Model\n",
    "    sf_lr = LinearRegression()\n",
    "    sf_lr.fit(x_train_feat, y_train_vec)\n",
    "    \n",
    "    # 4. Predictions & Metrics\n",
    "    y_pred_test = sf_lr.predict(x_test_feat)\n",
    "    residuals   = y_test_vec - y_pred_test\n",
    "    \n",
    "    r2_train = sf_lr.score(x_train_feat, y_train_vec)\n",
    "    r2_test  = r2_score(y_test_vec, y_pred_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test_vec, y_pred_test))\n",
    "\n",
    "    # 5. Create Line for Visualization (Min to Max of test data)\n",
    "    x_range = np.linspace(x_test_feat.min(), x_test_feat.max(), 100).reshape(-1, 1)\n",
    "    y_line  = sf_lr.predict(x_range)\n",
    "\n",
    "    # --- PLOT 1: Scatter + Line ---\n",
    "    scatter_fig = go.Figure()\n",
    "    # Actual Test Points (Gold)\n",
    "    scatter_fig.add_trace(go.Scatter(\n",
    "        x=x_test_feat.ravel(), y=y_test_vec,\n",
    "        mode='markers', name='Actual (Test)',\n",
    "        marker=dict(color=theme['accent'], opacity=0.8, size=8)\n",
    "    ))\n",
    "    # Fitted Line (White)\n",
    "    scatter_fig.add_trace(go.Scatter(\n",
    "        x=x_range.ravel(), y=y_line,\n",
    "        mode='lines', name='Fitted Line',\n",
    "        line=dict(color='white', width=3)\n",
    "    ))\n",
    "    scatter_fig.update_layout(\n",
    "        title=f\"{selected_feature} vs Golden Score\",\n",
    "        xaxis_title=selected_feature,\n",
    "        yaxis_title=\"Golden Score\",\n",
    "        template='plotly_dark',\n",
    "        plot_bgcolor=theme['card_bg'],\n",
    "        paper_bgcolor=theme['background'],\n",
    "        font_color=theme['text']\n",
    "    )\n",
    "\n",
    "    # --- PLOT 2: Residuals ---\n",
    "    resid_fig = go.Figure()\n",
    "    resid_fig.add_trace(go.Scatter(\n",
    "        x=x_test_feat.ravel(), y=residuals,\n",
    "        mode='markers', name='Residuals',\n",
    "        marker=dict(color=theme['accent'], opacity=0.8, size=8)\n",
    "    ))\n",
    "    # Zero line\n",
    "    resid_fig.add_hline(y=0, line=dict(color='red', dash='dash'))\n",
    "    resid_fig.update_layout(\n",
    "        title=f\"Residuals for {selected_feature}\",\n",
    "        xaxis_title=selected_feature,\n",
    "        yaxis_title=\"Residual (Actual - Pred)\",\n",
    "        template='plotly_dark',\n",
    "        plot_bgcolor=theme['card_bg'],\n",
    "        paper_bgcolor=theme['background'],\n",
    "        font_color=theme['text']\n",
    "    )\n",
    "\n",
    "    # --- SUMMARY TEXT ---\n",
    "    # Using the GLOBAL RidgeCV results for the text summary\n",
    "    coef_lines = [\n",
    "        html.P(f\"{feat}: {coef_map[feat]:.4f}\", style={'margin': 0, 'color': theme['text']})\n",
    "        for feat in predictive_cols\n",
    "    ]\n",
    "    \n",
    "    summary = html.Div([\n",
    "        html.H4(\"Multivariate Ridge Model Performance\", style={'color': theme['accent']}),\n",
    "        html.P(f\"Global Test R²: {R2_TEST:.3f}\", style={'fontWeight': 'bold'}),\n",
    "        html.P(f\"Global Test RMSE: {RMSE_TEST:.3f}\"),\n",
    "        html.P(f\"Best Alpha: {alpha_selected:.3f}\"),\n",
    "        html.Hr(style={'borderColor': theme['accent']}),\n",
    "        html.P(\"Feature Coefficients:\", style={'color': theme['accent']}),\n",
    "        html.Div(coef_lines, style={'paddingLeft': '20px'}), \n",
    "        html.H5(\"Conclusion:\", style={'color': theme['accent'], 'marginBottom': '6px'}),\n",
    "            html.P(\n",
    "                \"An L2 regularization is used on the linear model to stabilize the coefficients due to the raw facial measurements being highly correlated. \"\n",
    "                \"The single feature scatter plots above show the predictive relationship between golden_score and an individual predictor. \"\n",
    "                \"The scatterplots reveal that individual predictors have weak predictive power. However, when using a multivariate model,predictive accuracy increases. \"\n",
    "                \"A multivariate model results in a R² value of 0.926 and RMSE of about 0.94, indicating that a good proportion of variance in golden_score is explained by a multivariate linear model. \"\n",
    "                \"Therefore, raw individual measurements alone are insufficient in predicting golden ratio.\",\n",
    "                style={'color': theme['text'], 'fontSize': '16px', 'lineHeight': '1.6'}\n",
    "        )\n",
    "        ],\n",
    "        style={'padding':'16px','backgroundColor': theme['card_bg'],'border': f'1px solid {theme[\"accent\"]}','borderRadius':'8px','marginTop':'20px'})\n",
    "\n",
    "    return scatter_fig, resid_fig, summary\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
